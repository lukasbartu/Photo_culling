{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Quality\n",
    "- Brisque - https://pypi.org/project/brisque/\n",
    "- image-quality 1.2.7 - https://pypi.org/project/image-quality/\n",
    "- NIMA for aesthetic quality - https://github.com/yunxiaoshi/Neural-IMage-Assessment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f786a6e7de7ade7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For assessing image quality we have to consider two aspects. Technical and aesthetic quality of an image. Our usage involves no reference for quality assessment. We are going to look into how fast and sensitive the image quality evaluator is and evaluate which one is the most efficient for our use.\n",
    "\n",
    "For testing we created small folder with image and its various augmentations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26d94ea8f3d13875"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import time,os\n",
    "import torchvision.transforms as transforms\n",
    "# We create list of images that we use for testing\n",
    "\n",
    "image_path = '/home/lukas/Bakalářka/photo_culling/images/testing/'\n",
    "img_list = []  # list of image file names to process\n",
    "for path in os.scandir(image_path):\n",
    "    if path.is_file():\n",
    "        if path.name.endswith(\".jpg\"):\n",
    "            img_list += [path.name]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:01:47.093446557Z",
     "start_time": "2023-09-24T17:01:47.046689748Z"
    }
   },
   "id": "e30cf9e3f73ce306"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TECHNICAL QUALITY\n",
    "Firstly we are going to focus on technical quality. For technical quality we can choose from two approaches, one that is algorithmic and focused on scene statistics and the second one, which is using CNN trained on TID2013 dataset.\n",
    "\n",
    "For algorithmic approach we tested two implementations of the same algorithm called BRISQUE (Blind/referenceless image spatial quality evaluator). First implementation is library created by Rehan Guha (https://pypi.org/project/brisque/). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b81d75e55fe9ab"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME - 2.64 s\n",
      "['clear.jpg', 'GaussBlur.jpg', 'rotated.jpg', 'inverted.jpg', 'hue_shift.jpg', 'contrast.jpg']\n",
      "[17.485821795458577, 28.413960733575408, 33.273887398631786, 18.830194956031022, 12.740649274968945, 21.18914169633794]\n"
     ]
    }
   ],
   "source": [
    "from brisque import BRISQUE\n",
    "from skimage import io\n",
    "import torch,skimage\n",
    "\n",
    "obj = BRISQUE(url=False)\n",
    "results_BRISQUE = []\n",
    "\n",
    "tic = time.perf_counter()\n",
    "for img in img_list:\n",
    "    x = torch.tensor(io.imread(os.path.join(image_path, img)))/255.\n",
    "    x = skimage.transform.resize_local_mean(x, output_shape=[224,224])\n",
    "    results_BRISQUE.append(obj.score(x))\n",
    "toc = time.perf_counter()\n",
    "print(f\"TIME - {toc - tic:0.2f} s\")\n",
    "print(img_list)\n",
    "print(results_BRISQUE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:03:47.202592471Z",
     "start_time": "2023-09-24T17:03:44.545687370Z"
    }
   },
   "id": "85cbdd61b53f35d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this first test we can see that for this algorithm rotating and inverting has little to no effect. For shifted hue and increased contrast we can observe\n",
    "small change in quality score. And for Gaussian blur we can see the biggest quality score drop. This is expected as the technical quality should only be measured\n",
    "by pixels relation to its surroundings.\n",
    "\n",
    "Now we can try testing the second implementation of BRISQUE from image-quality library made by Ricardo Ocampo. In this implementation we need to open the images\n",
    "with Pillow image library function. This is slight downside."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2adfee4132c43ef6"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME - 1.64 s\n",
      "['clear.jpg', 'GaussBlur.jpg', 'rotated.jpg', 'inverted.jpg', 'hue_shift.jpg', 'contrast.jpg']\n",
      "[19.147925697235536, 25.563222094933366, 30.01686592807536, 21.257938204481405, 15.901238772803794, 21.22324834549758]\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import imquality.brisque\n",
    "\n",
    "results_BRISQUE = []\n",
    "\n",
    "tic = time.perf_counter()\n",
    "for img in img_list:\n",
    "    x = PIL.Image.open(os.path.join(image_path,img))\n",
    "    x.thumbnail((224,224))\n",
    "    x = imquality.brisque.score(x)\n",
    "    results_BRISQUE.append(x)\n",
    "toc = time.perf_counter()\n",
    "print(f\"TIME - {toc - tic:0.2f} s\")\n",
    "print(img_list)\n",
    "print(results_BRISQUE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:09:21.930088525Z",
     "start_time": "2023-09-24T17:09:20.281316111Z"
    }
   },
   "id": "5263bb5080c34aa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the second test we can observe the same as in the first one. The quality scores for both implementations are similar.\n",
    "\n",
    "Both of these solutions are very easy-to-use, give us single score number representing the technical quality and are linear in terms of computing time.\n",
    "\n",
    "TODO - try resizing the images beforehand to achieve faster computing times.\n",
    "\n",
    "\n",
    "Now we can go ahead and test CNN approach to technical quality assessment.\n",
    "- For this I haven't been able to test it yet. As I struggle to build the network with pretrained weights. TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0bc1cd2a4e9319"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO After testing CNN implementation we can decide which solution we will be using. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e378fff924e5da7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AESTHETIC QUALITY\n",
    "For aesthetics there are significantly fewer solutions as the question of aesthetics is vey subjective and so it's complicated to create an algorithmic solution.\n",
    "For this reason we are going to focus on deep learning approach with CNN trained on AVA dataset. This dataset is created with images of amateur photographers and as such they are focused on aesthetic quality to the images. The rating is trained on ratings of the public and hence it is as close to objective beauty rating as we can currently get. The output of the network is distribution of ratings that is simulating an actual distribution of ratings that people might give. From this distribution we are then able to get mean rating and the statistical deviation of the rating.\n",
    "\n",
    "We used implementation inspired by https://github.com/yunxiaoshi/Neural-IMage-Assessment. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afee0aca3102d95e"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME - 3.33 s\n",
      "['clear.jpg', 'GaussBlur.jpg', 'rotated.jpg', 'inverted.jpg', 'hue_shift.jpg', 'contrast.jpg']\n",
      "[(6.24, 1.21), (5.53, 1.47), (6.13, 1.32), (6.35, 1.49), (6.21, 1.27), (5.93, 1.37)]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NIMA(nn.Module):\n",
    "    \"\"\"Neural IMage Assessment model by Google\"\"\"\n",
    "    def __init__(self, base_model, num_classes=10):\n",
    "        super(NIMA, self).__init__()\n",
    "        self.features = base_model.features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.75),\n",
    "            nn.Linear(in_features=25088, out_features=num_classes),\n",
    "            nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_f = self.features(x)\n",
    "        out = out_f.view(out_f.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out_f,out\n",
    "\n",
    "base_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "model = NIMA(base_model)\n",
    "model.load_state_dict(torch.load(os.path.join(os.getcwd(), 'model.pth'), map_location=torch.device('cpu')))\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "            \n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "res_list = []\n",
    "mean, std = 0.0, 0.0\n",
    "tic = time.perf_counter()\n",
    "for img in img_list:\n",
    "    im = Image.open(os.path.join(image_path, str(img))).convert('RGB')\n",
    "    imt = test_transform(im)\n",
    "    imt = imt.unsqueeze(dim=0)\n",
    "    imt = imt.to(device)\n",
    "    with torch.no_grad():\n",
    "        out_f, out_class = model(imt)\n",
    "    out_class = out_class.view(10, 1)\n",
    "    for j, e in enumerate(out_class, 1):\n",
    "        mean += j * e\n",
    "    for k, e in enumerate(out_class, 1):\n",
    "        std += e * (k - mean) ** 2\n",
    "    std = std ** 0.5\n",
    "    mean = int(mean.item()*100)/100\n",
    "    std = int(std.item()*100)/100\n",
    "    res_list.append((mean,std))\n",
    "    mean, std = 0.0, 0.0\n",
    "toc = time.perf_counter()\n",
    "print(f\"TIME - {toc - tic:0.2f} s\")\n",
    "print(img_list)\n",
    "print(res_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:11:14.236225259Z",
     "start_time": "2023-09-24T17:11:07.319329077Z"
    }
   },
   "id": "34f751bf0ccb4f14"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results we can see that the technical quality is affecting the aesthetics quality as well.\n",
    "\n",
    "Considering that there aren't many more viable solutions for aesthetic quality assessment this will be likely solution that we will be using. That said the results seem to be satisfactory and are according to our expectations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c99a6d1cb0ce579"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7005f65ee8174947"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
